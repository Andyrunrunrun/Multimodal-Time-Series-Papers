# Multimodal-Time-Series-Papers
## Datasets
### Conference PapersğŸ“‘
| Paper                                                                                                                                         | Venue        | Month   | Category               | Code                                                       | Dataset                                                                                                   | Model                                                                                                   | Brief                                                                                                                                                                                         |
| --------------------------------------------------------------------------------------------------------------------------------------------- | ------------ | ------- | ---------------------- | ---------------------------------------------------------- | --------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset](https://arxiv.org/abs/2506.20093) | ICML 2025    | 2025.06 | QA_datasets+Multimodel | [Github](https://github.com/Pandalin98/ITFormer-ICML25)    | [Github](https://github.com/Pandalin98/ITFormer-ICML25)                                                   | â€”â€”                                                                                                      | 1. æå‡ºäº†èˆªç©ºå‘åŠ¨æœºå¤šä»»åŠ¡é—®ç­”æ•°æ®é›†**EngineMTâ€‘QA**æµ‹è¯•å¤šæ¨¡æ€æ—¶é—´åºåˆ—æ¨¡å‹çš„èƒ½åŠ› <br> 2. **ITFormer**ç»“æ„è®©å¤§æ¨¡å‹å¯ä»¥çœ‹æ‡‚æ—¶é—´åºåˆ—æ•°æ®                                                                                                         |
| [ChatTime: A Unified Multimodal Time Series Foundation Model Bridging Numerical and Textual Data](https://arxiv.org/abs/2412.11376)           | AAAI 2025    | 2025.05 | QA_datasets+Multimodel | [Github](https://github.com/ForestsKing/ChatTime)          | [Huggingface](https://huggingface.co/collections/ChengsenWang/chattime-datasets-6731b504efecc8a6e439741c) | [Huggingface](https://huggingface.co/collections/ChengsenWang/chattime-models-6731b650cb98bc7842713fde) | å°†æ—¶é—´åºï¦œå»ºæ¨¡ä¸ºä¸€ç§å¤–è¯­ï¼Œå¹¶æ„å»ºï¦º ChatTimeï¼Œä¸€ä¸ªç”¨äºæ—¶é—´åºï¦œå’Œæ–‡æœ¬å¤„ï§¤çš„ç»Ÿä¸€æ¡†æ¶ã€‚ä½œä¸ºä¸€ä¸ªå¼€ç®±å³ç”¨çš„å¤šæ¨¡æ€æ—¶é—´åºï¦œåŸºç¡€æ¨¡å‹ï¼ŒChatTime æä¾›é›¶æ ·æœ¬é¢„æµ‹èƒ½ï¦Šï¼Œå¹¶æ”¯æŒæ—¶é—´åºï¦œå’Œæ–‡æœ¬çš„åŒæ¨¡æ€è¾“å…¥ / è¾“å‡ºã€‚                                                                                  |
| [Time-MQA: Time Series Multi-Task Question Answering with Context Enhancement](https://arxiv.org/abs/2503.01875)                              | ACL 2025     | 2025.05 | QA_datasets            | â€”â€”                                                         | [Huggingface](https://huggingface.co/Time-MQA)                                                            | [Huggingface](https://huggingface.co/Time-MQA)                                                          | é€šè¿‡è‡ªç„¶è¯­è¨€æŸ¥è¯¢å°†å¤šç§æ—¶é—´åºåˆ—åˆ†æä»»åŠ¡ç»Ÿä¸€èµ·æ¥ï¼Œåˆ›å»ºäº†ä¸€ä¸ªåŒ…å«çº¦20ä¸‡ä¸ªé—®ç­”å¯¹çš„å¤§è§„æ¨¡æ•°æ®é›†TSQA ã€‚é€šè¿‡åœ¨TSQAæ•°æ®é›†ä¸Šå¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œè¯æ˜æ¨¡å‹åœ¨è§£é‡Šæ—¶é—´åºåˆ—æ¨¡å¼å’Œå¤„ç†éœ€è¦æ¨ç†çš„å¤æ‚é—®é¢˜æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—å¢å¼ºçš„èƒ½åŠ›ï¼Œä»è€Œå°†ä¼ ç»Ÿçš„æ•°å€¼ä»»åŠ¡ä¸ç°ä»£è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ç›¸ç»“åˆ                                                   |
| [Time-MMD: Multi-Domain Multimodal Dataset for Time Series Analysis](https://arxiv.org/abs/2406.08627)                                        | NuerIPS 2024 | 2025.02 | Multimodel_datasets    | [Github](https://github.com/AdityaLab/Time-MMD)            | [Github](https://github.com/AdityaLab/Time-MMD)                                                           | â€”â€”                                                                                                      | Time-MMDâ€”â€”é¦–ä¸ªè¦†ç›–9ä¸ªä¸åŒé¢†åŸŸã€å°†æ•°å€¼åºåˆ—ä¸æ–‡æœ¬ä¿¡æ¯ç²¾ç»†å¯¹é½çš„å¤§å‹å¤šæ¨¡æ€æ•°æ®é›†ã€‚åŒæ—¶ï¼Œä½œè€…è¿˜å¼€å‘äº†é…å¥—çš„è½¯ä»¶åº“ MM-TSFlibï¼Œå¹¶é€šè¿‡å¤§é‡å®éªŒè¯æ˜ï¼Œåœ¨è¿™ç§é«˜è´¨é‡æ•°æ®ä¸Šç»“åˆæ–‡æœ¬ä¿¡æ¯å¯ä»¥ä½¿æ—¶é—´åºåˆ—çš„é¢„æµ‹å‡†ç¡®ç‡è·å¾—å·¨å¤§æå‡ï¼ˆMSEå¹³å‡é™ä½è¶…15%ï¼‰ã€‚                                                             |
| [Language Models Still Struggle to Zero-shot Reason about Time Series](https://arxiv.org/abs/2404.11757)                                      | ACL  2024    | 2024.12 | Multimodel_datasets    | [Github](https://github.com/behavioral-data/TSandLanguage) | [Github](https://github.com/behavioral-data/TSandLanguage)                                                | â€”â€”                                                                                                      | æ•°æ®é›†åŒ…å«87,000å¯¹æ—¶é—´åºåˆ—ä¸æ–‡æœ¬æè¿°ï¼Œæ¶µç›–äº†åŒ»ç–—ä¿å¥ã€é‡‘èã€å†œä¸šã€äº¤é€šã€å¨±ä¹ç­‰10ä¸ªé¢†åŸŸã€‚é€šè¿‡åˆ›å»ºä¸€ä¸ªå…¨æ–°çš„è¯„ä¼°æ¡†æ¶å’Œæ•°æ®é›†ï¼Œæ¥æ£€éªŒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLMsï¼‰æ˜¯å¦çœŸæ­£å…·å¤‡å¯¹æ—¶é—´åºåˆ—çš„æ¨ç†èƒ½åŠ›ï¼Œè€Œä¸ä»…ä»…æ˜¯è¿›è¡Œæ¨¡å¼åŒ¹é…å¼çš„é¢„æµ‹ ã€‚ç ”ç©¶å‘ç°ï¼Œå³ä½¿æ˜¯åƒGPT-4è¿™æ ·å¼ºå¤§çš„æ¨¡å‹ï¼Œåœ¨è¯†åˆ«æ—¶é—´åºåˆ—æˆå› ã€å›ç­”ç›¸å…³é—®é¢˜ç­‰æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°ä¹Ÿå‡ºäººæ„æ–™åœ°å·®ï¼Œå…¶å¾—åˆ†ä»…ç•¥é«˜äºéšæœºçŒœæµ‹ï¼Œè¿œé€Šäºäººç±»æ°´å¹³ ã€‚ |
| [T2S: High-resolution Time Series Generation with Text-to-Series Diffusion Models](https://arxiv.org/abs/2505.02417)                          | IJCAI 2025   | 2024.06 | Multimodel_datasets    | [Github](https://github.com/WinfredGe/T2S)                 | [Github](https://github.com/WinfredGe/T2S)                                                                | â€”â€”                                                                                                      | å¼•å…¥äº†ä¸€ä¸ªåŒ…å«è¶…è¿‡60ä¸‡ä¸ªé«˜åˆ†è¾¨ç‡æ—¶é—´åºåˆ—-æ–‡æœ¬å¯¹çš„æ–°æ•°æ®é›†TSFragment-600Kï¼Œä»¥è§£å†³æ–‡æœ¬åˆ°æ—¶é—´åºåˆ—ç”Ÿæˆé¢†åŸŸä¸­æ•°æ®é›†ç¨€ç¼ºå’Œç‰¹å®šé¢†åŸŸçš„é—®é¢˜ ã€‚å…¶æ¬¡ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºT2Sçš„ã€åŸºäºæ‰©æ•£çš„é¢†åŸŸæ— å…³æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨é•¿åº¦è‡ªé€‚åº”å˜åˆ†è‡ªç¼–ç å™¨å’Œæ‰©æ•£å˜æ¢å™¨ï¼Œèƒ½å¤Ÿæ ¹æ®è‡ªç„¶è¯­è¨€æè¿°ç”Ÿæˆä»»æ„é•¿åº¦çš„é«˜ä¿çœŸæ—¶é—´åºåˆ— ã€‚                                    |
| [MoTime: A Dataset Suite for Multimodal Time Series Forecasting](https://arxiv.org/abs/2505.15072)                                            | arxiv        | 2024.04 | Multimodel_datasets    | â€”â€”                                                         | [Kaggle](https://www.kaggle.com/datasets/krissssss/multimodal-time-series-forecasting/)                   | â€”â€”                                                                                                      | MoTimeæ˜¯ä¸€å¥—ç»¼åˆæ€§çš„å¤šæ¨¡æ€æ—¶é—´åºåˆ—é¢„æµ‹æ•°æ®é›†ï¼Œé€šè¿‡æ•´åˆå¤šç§æ•°æ®æºæ¥æé«˜é¢„æµ‹å‡†ç¡®æ€§ï¼Œè§£å†³äº†ä¼ ç»Ÿå•æ¨¡æ€æ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶ä¸ºåœ¨ä¸åŒå†å²æ•°æ®å’Œå†·å¯åŠ¨åœºæ™¯ä¸‹çš„ç ”ç©¶äººå‘˜æä¾›äº†å®è´µçš„èµ„æºã€‚                                                                                                     |
| [PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting](https://arxiv.org/abs/2210.08964)                              | TKDE         | 2022.09 | Multimodel_datasets    | [Github](https://github.com/HaoUNSW/PISA)                  | [Github](https://github.com/HaoUNSW/PISA)                                                                 | â€”â€”                                                                                                      | å°†ä¼ ç»Ÿçš„æ•°å€¼è¾“å…¥è¾“å‡ºåºåˆ—è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€æç¤ºï¼Œä»è€Œå°†é¢„æµ‹ä»»åŠ¡æ„å»ºä¸ºä¸€ä¸ªå¥é—´ç”Ÿæˆé—®é¢˜ï¼Œä½¿å¾—åº”ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œé¢„æµ‹æˆä¸ºå¯èƒ½ ã€‚ä¸ºäº†æ”¯æŒè¿™ä¸€æ–°ä»»åŠ¡ï¼Œä½œè€…è¿˜å‘å¸ƒäº†ä¸€ä¸ªåä¸ºPISAçš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«ä¸‰ç§çœŸå®çš„é¢„æµ‹åœºæ™¯ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªåŸºå‡†æ¥è¯„ä¼°è¯­è¨€ç”Ÿæˆæ¨¡å‹åœ¨æ­¤ä»»åŠ¡ä¸Šçš„è¡¨ç° ã€‚                                                      |

## Models
### Conference PapersğŸ“‘
| Paper                                                                                                                                            | Venue        | Month   | Category                                                                       | Tasks                   | Algorithm       | Code                                                                      | GPU                     | Dataset                                                                                                   | Model                                                                                                   | Brief                                                                                                                                                       |
| ------------------------------------------------------------------------------------------------------------------------------------------------ | ------------ | ------- | ------------------------------------------------------------------------------ | ----------------------- | --------------- | ------------------------------------------------------------------------- | ----------------------- | --------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting](https://arxiv.org/abs/2310.09751)                         | www 2024     | 2023.10 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | MLLM-based      | [Github](https://github.com/DAMO-DI-ML/)                                  | A100 80GB               | [Github](https://github.com/DAMO-DI-ML/)                                                                  | â€”â€”                                                                                                      | è§£å†³ä¸ºä¸åŒæ—¶é—´åºåˆ—é¢†åŸŸæ„å»ºä¸“ç”¨æ¨¡å‹ï¼ˆdomain-specificï¼‰çš„å±€é™æ€§ï¼Œä»è€Œå®ç°è·¨é¢†åŸŸçš„æ—¶é—´åºåˆ—é¢„æµ‹ã€‚è¯¥æ¨¡å‹åˆ©ç”¨è¯­è¨€æ¨¡å‹ä½œä¸ºåŸºç¡€ï¼Œé€šè¿‡å¼•å…¥â€œé¢†åŸŸæŒ‡ä»¤â€æ¥åŒºåˆ†ä¸åŒé¢†åŸŸçš„æ•°æ®å¹¶å¯¹é½ä¸¤ç§æ¨¡æ€ï¼ŒåŒæ—¶é‡‡ç”¨æ©ç ï¼ˆmaskingï¼‰ç­–ç•¥æ¥å¹³è¡¡ä¸åŒé¢†åŸŸçš„æ”¶æ•›é€Ÿåº¦ï¼Œæœ€ç»ˆåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å±•ç°äº†å“è¶Šçš„é¢„æµ‹æ€§èƒ½å’Œé›¶æ ·æœ¬è¿ç§»èƒ½åŠ›ã€‚ |
| [ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset](https://arxiv.org/abs/2506.20093)    | ICML 2025    | 2025.6  | QA_datasets+Multimodel                                                         | Time Series Analysis    | MLLM-based      | [Github](https://github.com/Pandalin98/ITFormer-ICML25)                   | 4*H100                  | [Github](https://github.com/Pandalin98/ITFormer-ICML25)                                                   | â€”â€”                                                                                                      | 1. æå‡ºäº†èˆªç©ºå‘åŠ¨æœºå¤šä»»åŠ¡é—®ç­”æ•°æ®é›†**EngineMTâ€‘QA**æµ‹è¯•å¤šæ¨¡æ€æ—¶é—´åºåˆ—æ¨¡å‹çš„èƒ½åŠ› 2. **ITFormer**ç»“æ„è®©å¤§æ¨¡å‹å¯ä»¥çœ‹æ‡‚æ—¶é—´åºåˆ—æ•°æ®                                                                            |
| [T2S: High-resolution Time Series Generation with Text-to-Series Diffusion Models](https://arxiv.org/abs/2505.02417)                             | IJCAI 2025   | 2025.05 | Multimodel_datasets                                                            | Time Series Generation  | Diffusion-based | [Github](https://github.com/WinfredGe/T2S)                                | â€”â€”                      | [Github](https://github.com/WinfredGe/T2S)                                                                | â€”â€”                                                                                                      | å¼•å…¥äº†ä¸€ä¸ªåŒ…å«è¶…è¿‡60ä¸‡ä¸ªé«˜åˆ†è¾¨ç‡æ—¶é—´åºåˆ—-æ–‡æœ¬å¯¹çš„æ–°æ•°æ®é›†TSFragment-600Kï¼Œä»¥è§£å†³æ–‡æœ¬åˆ°æ—¶é—´åºåˆ—ç”Ÿæˆé¢†åŸŸä¸­æ•°æ®é›†ç¨€ç¼ºå’Œç‰¹å®šé¢†åŸŸçš„é—®é¢˜ã€‚å…¶æ¬¡ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºT2Sçš„ã€åŸºäºæ‰©æ•£çš„é¢†åŸŸæ— å…³æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨é•¿åº¦è‡ªé€‚åº”å˜åˆ†è‡ªç¼–ç å™¨å’Œæ‰©æ•£å˜æ¢å™¨ï¼Œèƒ½å¤Ÿæ ¹æ®è‡ªç„¶è¯­è¨€æè¿°ç”Ÿæˆä»»æ„é•¿åº¦çš„é«˜ä¿çœŸæ—¶é—´åºåˆ—ã€‚    |
| [TimeCMA: Towards LLM-Empowered Multivariate Time Series Forecasting via Cross-Modality Alignment](https://arxiv.org/abs/2406.01638)             | AAAI 2025    | 2025.03 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | MLLM-based      | [Github](https://github.com/ChenxiLiu-HNU/TimeCMA)                        | NVIDIA A100 GPU         | â€”â€”                                                                                                        | â€”â€”                                                                                                      | TimeCMAé€šè¿‡åŒæ¨¡æ€ç¼–ç ï¼ˆæ—¶é—´åºåˆ—ç¼–ç ä¸LLMèµ‹èƒ½çš„æç¤ºç¼–ç ï¼‰å’Œè·¨æ¨¡æ€å¯¹é½æ¨¡å—ï¼Œåˆ©ç”¨åŸºäºç›¸ä¼¼åº¦çš„æ£€ç´¢ä»çº ç¼ çš„æç¤ºåµŒå…¥ä¸­è·å–å»è€¦ä¸”ç¨³å¥çš„æ—¶é—´åºåˆ—åµŒå…¥ã€‚                                                                                |
| [Time-VLM: Exploring Multimodal Vision-Language Models for Augmented Time Series Forecasting](https://arxiv.org/abs/2502.04395)                  | CVPR 2025    | 2025.02 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | MLLM-based      | [Github](https://github.com/CityMind-Lab/ICML25-TimeVLM)                  | RTX A6000 GPU (48GB)    | â€”â€”                                                                                                        | â€”â€”                                                                                                      | ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰å°†æ—¶é—´ã€è§†è§‰å’Œæ–‡æœ¬ä¸‰ç§æ¨¡æ€ç»“åˆèµ·æ¥ï¼Œä»¥è§£å†³ä»¥å¾€æ—¶é—´åºåˆ—é¢„æµ‹ä¸­ä»…ä½¿ç”¨å•ä¸€æ¨¡æ€ï¼ˆæ–‡æœ¬æˆ–è§†è§‰ï¼‰è¿›è¡Œå¢å¼ºæ‰€å¸¦æ¥çš„å±€é™æ€§ã€‚                                                                                   |
| [TimeCAP: Learning to Contextualize, Augment, and Predict Time Series Events with Large Language Model Agents](https://arxiv.org/abs/2310.01728) | AAAI2025     | 2025.02 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Analysis    | LLM-based       | [Github](https://github.com/geon0325/TimeCAP)                             | â€”â€”                      | [Github](https://github.com/geon0325/TimeCAP)                                                             | â€”â€”                                                                                                      | åˆ›æ–°æ€§åœ°ä½¿ç”¨ä¸¤ä¸ªç‹¬ç«‹çš„LLM agentsæ¥å¤„ç†æ—¶é—´åºåˆ—äº‹ä»¶é¢„æµ‹ã€‚å…¶ä¸­ï¼Œç¬¬ä¸€ä¸ªæ™ºèƒ½ä½“è´Ÿè´£å°†åŸå§‹æ—¶é—´åºåˆ—â€œæƒ…å¢ƒåŒ–â€ä¸ºä¸€ä»½è¯¦å°½çš„æ–‡æœ¬æ‘˜è¦ï¼Œè€Œç¬¬äºŒä¸ªæ™ºèƒ½ä½“åˆ™åˆ©ç”¨è¿™ä»½æ‘˜è¦ï¼ˆè€ŒéåŸå§‹æ•°æ®ï¼‰è¿›è¡Œæ›´ç²¾å‡†çš„é¢„æµ‹ï¼Œå¹¶é€šè¿‡ä¸€ä¸ªå¤šæ¨¡æ€ç¼–ç å™¨è¿›è¡ŒååŒå¢å¼ºã€‚                                        |
| [ChatTime: A Unified Multimodal Time Series Foundation Model Bridging Numerical and Textual Data](https://arxiv.org/abs/2412.11376)              | AAAI 2025    | 2024.12 | QA_datasets+Multimodel                                                         | Time Series Forecasting | MLLM-based      | [Github](https://github.com/ForestsKing/ChatTime)                         | NVIDIA GeForce RTX 4090 | [Huggingface](https://huggingface.co/collections/ChengsenWang/chattime-datasets-6731b504efecc8a6e439741c) | [Huggingface](https://huggingface.co/collections/ChengsenWang/chattime-models-6731b650cb98bc7842713fde) | å°†æ—¶é—´åºåˆ—å»ºæ¨¡ä¸ºä¸€ç§å¤–è¯­ï¼Œå¹¶æ„å»ºäº†ChatTimeï¼Œä¸€ä¸ªç”¨äºæ—¶é—´åºåˆ—å’Œæ–‡æœ¬å¤„ç†çš„ç»Ÿä¸€æ¡†æ¶ã€‚ä½œä¸ºä¸€ä¸ªå¼€ç®±å³ç”¨çš„å¤šæ¨¡æ€æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹ï¼ŒChatTime æä¾›é›¶æ ·æœ¬é¢„æµ‹èƒ½åŠ›ï¼Œå¹¶æ”¯æŒæ—¶é—´åºåˆ—å’Œæ–‡æœ¬çš„åŒæ¨¡æ€è¾“å…¥/è¾“å‡ºã€‚                                                   |
| [Time Series Forecasting with LLMs: Understanding and Enhancing Model Capabilities](https://arxiv.org/abs/2402.10835)                            | SIGKDD       | 2024.12 | Enhance time series with language.(Time series + Language IN, Language OUT)    | Time Series Forecasting | LLM-based       | [Github](https://github.com/MingyuJ666/Time-Series-Forecasting-with-LLMs) | â€”â€”                      | â€”â€”                                                                                                        | â€”â€”                                                                                                      | æ¢ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é›¶æ ·æœ¬æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„ç‰¹æ€§ï¼Œå‘ç°å®ƒä»¬åœ¨å¤„ç†å…·æœ‰æ˜æ˜¾è¶‹åŠ¿å’Œå­£èŠ‚æ€§æ¨¡å¼çš„æ•°æ®æ—¶è¡¨ç°æ›´ä½³ï¼Œå¹¶ä¸”èƒ½è¯†åˆ«å‡ºæ•°æ®ä¸­çš„æ½œåœ¨å‘¨æœŸã€‚è®ºæ–‡æå‡ºäº†ä¸¤ç§æ— éœ€é¢å¤–å¾®è°ƒçš„æ€§èƒ½æå‡æ–¹æ³•ï¼šåœ¨æç¤ºä¸­èå…¥å…³äºæ•°æ®é›†çš„å¤–éƒ¨çŸ¥è¯†ï¼Œä»¥åŠå°†æ•°å€¼åºåˆ—è½¬è¿°ä¸ºè‡ªç„¶è¯­è¨€æè¿°ï¼Œè¿™ä¸¤ç§æ–¹æ³•éƒ½è¢«è¯æ˜èƒ½æ˜¾è‘—æ”¹å–„é¢„æµ‹æ•ˆæœã€‚               |
| [From News to Forecast: Integrating Event Analysis in LLM-Based Time Series Forecasting with Reflection](https://arxiv.org/abs/2409.17515)       | NeurIPS 2024 | 2024.09 | Enhance time series with language.(Time series + Language IN, Language OUT)    | Time Series Forecasting | LLM-based       | [Github](https://github.com/ameliawong1996/From_News_to_Forecast)         | â€”â€”                      | â€”â€”                                                                                                        | â€”â€”                                                                                                      | é€šè¿‡æ•´åˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œç”Ÿæˆä»£ç†ï¼Œå°†éç»“æ„åŒ–çš„æ–°é—»æ•°æ®ä¸æ•°å€¼æ—¶é—´åºåˆ—ç›¸ç»“åˆï¼Œä»è€Œå¢å¼ºäº†é¢„æµ‹èƒ½åŠ›ã€‚ç ”ç©¶åˆ©ç”¨åŸºäºLLMçš„ä»£ç†æ¥è¿­ä»£å¼åœ°ç­›é€‰ç›¸å…³æ–°é—»ï¼Œå¹¶é€šè¿‡ç±»ä¼¼äººç±»çš„æ¨ç†æ¥è¯„ä¼°é¢„æµ‹ï¼ŒæŒç»­ä¼˜åŒ–æ–°é—»é€‰æ‹©é€»è¾‘ï¼Œç„¶åå¾®è°ƒä¸€ä¸ªé¢„è®­ç»ƒçš„LLMæ¥è¿›è¡Œé¢„æµ‹ï¼Œå®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ³•æ˜¾è‘—æé«˜äº†é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚            |
| [GPT4MTS: Prompt-Based Large Language Model for Multimodal Time-Series Forecasting](https://ojs.aaai.org/index.php/AAAI/article/view/30383)      | AAAI 2024    | 2024.03 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | MLLM-based      | â€”â€”                                                                        | â€”â€”                      | â€”â€”                                                                                                        | â€”â€”                                                                                                      | æå‡ºäº†ä¸€ä¸ªé€šç”¨æµç¨‹ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸ºæ—¶é—´åºåˆ—æ•°æ®æ”¶é›†å’Œæ€»ç»“ç›¸å…³çš„æ–‡æœ¬ä¿¡æ¯ï¼Œä»¥è§£å†³å¤šæ¨¡æ€æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ã€‚è¿˜æå‡ºäº†ä¸€ç§åä¸ºGPT4MTSçš„åŸºäºæç¤ºçš„LLMæ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½åŒæ—¶åˆ©ç”¨æ•°å€¼å’Œæ–‡æœ¬ä¿¡æ¯è¿›è¡Œé¢„æµ‹ï¼Œå¹¶é€šè¿‡åœ¨ä¸€ä¸ªæ–°å»ºçš„GDELTæ–°é—»å½±å“æ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒï¼Œè¯æ˜äº†å…¶åœ¨å¤šæ¨¡æ€æ—¶é—´åºåˆ—é¢„æµ‹ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚        |
| [S2IPâ€‘LLM](https://arxiv.org/abs/2403.05798)                                                                                                     | ICML 2024    | 2024.03 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | LLM-based       | [Github](https://github.com/panzijie825/S2IP-LLM)                         | A100 80GB               | â€”â€”                                                                                                        | â€”â€”                                                                                                      | é¦–å…ˆå°†æ—¶é—´åºåˆ—åˆ†è§£ä¸ºè¶‹åŠ¿ã€å­£èŠ‚æ€§å’Œæ®‹å·®éƒ¨åˆ†ä»¥åˆ›å»ºæ›´å…·è¡¨ç°åŠ›çš„åµŒå…¥ï¼Œç„¶åé€šè¿‡æœ€å¤§åŒ–ä½™å¼¦ç›¸ä¼¼åº¦å°†å…¶ä¸ä»LLMè¯æ±‡ä¸­æå–çš„â€œè¯­ä¹‰é”šç‚¹â€å¯¹é½ï¼Œå¹¶ä½¿ç”¨æœ€ç›¸å…³çš„é”šç‚¹ä½œä¸ºæç¤ºæ¥å¢å¼ºé¢„æµ‹ï¼Œæœ€ç»ˆåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†ä¼˜äºç°æœ‰é¡¶å°–æ–¹æ³•çš„é¢„æµ‹æ€§èƒ½ã€‚                                          |
| [LLM Processes: Numerical Predictive Distributions Conditioned on Natural Language](https://arxiv.org/abs/2405.12856)                            | NeurIPS 2024 | 2024.03 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | LLM-based       | [Github](https://github.com/requeima/llm_processes)                       | 2*A100 80GB             | â€”â€”                                                                                                        | â€”â€”                                                                                                      | åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆå¯å¤„ç†ä»»æ„ä½ç½®æ•°å€¼æ•°æ®çš„æ¦‚ç‡æ€§é¢„æµ‹ï¼Œå¹¶ä¸”è¿™äº›é¢„æµ‹å¯ä»¥é€šè¿‡è‡ªç„¶è¯­è¨€æ–‡æœ¬æ¥å¼•å¯¼å’Œè°ƒæ•´ã€‚é€šè¿‡å¼€å‘æœ‰æ•ˆçš„æç¤ºç­–ç•¥ï¼Œè¯¥ç ”ç©¶è¯æ˜äº†LLMPsä¸ä»…åœ¨å›å½’å’Œé¢„æµ‹ä»»åŠ¡ä¸Šä¸é«˜æ–¯è¿‡ç¨‹ç­‰ä¸“ç”¨æ¨¡å‹å…·æœ‰ç«äº‰åŠ›ï¼Œè¿˜èƒ½æˆåŠŸåœ°å°†å®šæ€§çš„æ–‡æœ¬æè¿°èå…¥å®šé‡é¢„æµ‹ä¸­ï¼Œä»è€Œåˆ©ç”¨LLMsä¸­è•´å«çš„ä¸°å¯ŒçŸ¥è¯†ã€‚            |
| [CAN LLMS UNDERSTAND TIME SERIES ANOMALIES?](https://arxiv.org/abs/2410.05440)                                                                   | ICLR 2025    | 2024.01 | Reasoning                                                                      | TIME SERIES ANOMALIES   | LLM-based       | [Github](https://github.com/rose-stl-lab/anomllm)                         | â€”â€”                      | â€”â€”                                                                                                        | â€”â€”                                                                                                      | é€šè¿‡ä¸€ç³»åˆ—å—æ§å®éªŒï¼Œç³»ç»Ÿæ€§åœ°æ¢ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ˜¯å¦çœŸæ­£ç†è§£æ—¶é—´åºåˆ—ä¸­çš„å¼‚å¸¸ã€‚å…¶æ ¸å¿ƒå‘ç°é¢ è¦†äº†æ™®éè®¤çŸ¥ï¼šLLMså°†æ—¶é—´åºåˆ—ä½œä¸ºå›¾åƒç†è§£æ—¶è¡¨ç°è¿œå¥½äºæ–‡æœ¬ï¼Œå¹¶ä¸”â€œé“¾å¼æ€è€ƒâ€ç­‰å¼•å¯¼å…¶è¿›è¡Œé€»è¾‘æ¨ç†çš„æç¤ºåè€Œä¼šé™ä½å…¶æ€§èƒ½ï¼Œè¡¨æ˜LLMå¯¹æ—¶åºæ•°æ®çš„ç†è§£æœºåˆ¶å¹¶éæºäºå…¶é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚                  |
| [Large Language Models Are Zero-Shot Time Series Forecasters](https://arxiv.org/abs/2310.07820)                                                  | NurIPS 2023  | 2023.01 | Enhance time series with language.(Time series + Language IN, Language OUT)    | Time Series Forecasting | LLM-based       | [Github](https://github.com/ngruver/llmtime)                              | â€”â€”                      | â€”â€”                                                                                                        | â€”â€”                                                                                                      | é€šè¿‡å°†æ—¶é—´åºåˆ—æ•°æ®ç¼–ç ä¸ºæ•°å­—å­—ç¬¦ä¸²ï¼ŒæˆåŠŸåœ°å°†æ—¶é—´åºåˆ—é¢„æµ‹é—®é¢˜è½¬åŒ–ä¸ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ä¸‹ä¸€æ–‡æœ¬é¢„æµ‹ä»»åŠ¡ã€‚ç ”ç©¶å‘ç°ï¼ŒåƒGPT-3å’ŒLLaMA-2è¿™æ ·çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œåœ¨æ— éœ€é’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œè®­ç»ƒçš„æƒ…å†µä¸‹ï¼ˆå³é›¶æ ·æœ¬ï¼‰ï¼Œå…¶é¢„æµ‹æ€§èƒ½å¯ä»¥åª²ç¾ç”šè‡³è¶…è¶Šé‚£äº›ä¸“é—¨ä¸ºæ—¶é—´åºåˆ—ä»»åŠ¡æ„å»ºå’Œè®­ç»ƒçš„æ¨¡å‹ã€‚                |
| [TIME-LLM: TIME SERIES FORECASTING BY REPROGRAMMING LARGE LANGUAGE MODELS](https://arxiv.org/abs/2310.01728)                                     | ICLR 2024    | 2023.01 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | MLLM-based      | [Github](https://github.com/KimMeen/Time-LLM)                             | 8*A800 (80GB)           | â€”â€”                                                                                                        | â€”â€”                                                                                                      | é€šè¿‡é‡ç¼–ç¨‹æŠ€æœ¯ï¼Œå°†æ—¶é—´åºåˆ—æ•°æ®è½¬åŒ–ä¸ºå¤§è¯­è¨€æ¨¡å‹çœ‹çš„æ‡‚çš„è¯­è¨€ï¼Œå°†æ—¶é—´åºåˆ—é¢„æµ‹å·§å¦™åœ°è½¬åŒ–ä¸ºäº†ä¸€ä¸ª LLM å¯ä»¥ç›´æ¥å¤„ç†çš„â€œç±»è¯­è¨€â€ä»»åŠ¡ã€‚                                                                                          |
| [PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting](https://arxiv.org/abs/2210.08964)                                 | TKDE 2023    | 2022.09 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | LLM-based       | [Github](https://github.com/HaoUNSW/PISA)                                 | â€”â€”                      | [Github](https://github.com/HaoUNSW/PISA)                                                                 | â€”â€”                                                                                                      | å°†ä¼ ç»Ÿçš„æ•°å€¼è¾“å…¥è¾“å‡ºåºåˆ—è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€æç¤ºï¼Œä»è€Œå°†é¢„æµ‹ä»»åŠ¡æ„å»ºä¸ºä¸€ä¸ªå¥é—´ç”Ÿæˆé—®é¢˜ï¼Œä½¿å¾—åº”ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œé¢„æµ‹æˆä¸ºå¯èƒ½ã€‚ä¸ºäº†æ”¯æŒè¿™ä¸€æ–°ä»»åŠ¡ï¼Œä½œè€…è¿˜å‘å¸ƒäº†ä¸€ä¸ªåä¸ºPISAçš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«ä¸‰ç§çœŸå®çš„é¢„æµ‹åœºæ™¯ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªåŸºå‡†æ¥è¯„ä¼°è¯­è¨€ç”Ÿæˆæ¨¡å‹åœ¨æ­¤ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚                      |


### PreprintğŸ“š
| Paper                                                                                                                              | Venue | Month   | Category                                                                                  | Tasks                      | Algorithm  | Code                                              | GPU        | Dataset | Model | Brief                                                                                                                                                                |
| ---------------------------------------------------------------------------------------------------------------------------------- | ----- | ------- | ----------------------------------------------------------------------------------------- | -------------------------- | ---------- | ------------------------------------------------- | ---------- | ------- | ----- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Time Series Forecasting as Reasoning: A Slow-Thinking Approach with Reinforced LLMs](https://arxiv.org/abs/2506.10630)            | arxiv | 2025.06 | Enhance time series with language.(Time series + Language IN, Time series + Language OUT) | â€”â€”                         | LLM-based  | [Github](https://github.com/lqzxt/Time-R1)        | 4*A800     | â€”â€”      | â€”â€”    | æå‡ºäº†ä¸€ç§åä¸ºTime-R1çš„æ–°é¢–æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å…·å¤‡â€œæ…¢æ€è€ƒâ€èƒ½åŠ›ï¼Œä»è€Œå°†æ—¶é—´åºåˆ—é¢„æµ‹ä»ä¼ ç»Ÿçš„æ¨¡å¼åŒ¹é…è½¬å˜ä¸ºä¸€ä¸ªæ˜¾å¼çš„æ¨ç†è¿‡ç¨‹ã€‚è¯¥æ¡†æ¶é‡‡ç”¨ä¸€ä¸ªä¸¤é˜¶æ®µçš„å¼ºåŒ–å¾®è°ƒæ–¹æ³•ï¼šé¦–å…ˆé€šè¿‡ç›‘ç£å¼å¾®è°ƒè¿›è¡Œé¢„çƒ­ï¼Œç„¶ååˆ©ç”¨ä¸€ç§æ–°çš„ã€å¸¦æœ‰ç»†ç²’åº¦å¤šç›®æ ‡å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼ˆGRIPï¼‰æ¥ä¼˜åŒ–æ¨¡å‹çš„æ¨ç†è·¯å¾„ï¼Œä»è€Œæ˜¾è‘—æå‡é¢„æµ‹æ€§èƒ½ã€‚ |
| [ChronoSteer: Bridging Large Language Model and Time Series Foundation Model via Synthetic Data](https://arxiv.org/abs/2505.10083) | arxiv | 2025.05 | Enhance time series with language.(Time series + Language IN, Time series OUT)            | Time Series Forecasting    | MLLM-based | â€”â€”                                                | 4090 24GB  | â€”â€”      | â€”â€”    | åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å°†æ–‡æœ¬äº‹ä»¶ï¼ˆå¦‚å¤©æ°”é¢„æŠ¥ï¼‰è½¬è¯‘ä¸ºç®€å•çš„â€œä¿®è®¢æŒ‡ä»¤â€ï¼ˆå¦‚â€œæé«˜å³°å€¼â€ï¼‰ï¼Œç”¨ä»¥ç›´æ¥å¼•å¯¼ä¸€ä¸ªæ—¶é—´åºåˆ—æ¨¡å‹ï¼ˆTSFMï¼‰åšå‡ºæ›´å‡†ç¡®çš„é¢„æµ‹ï¼Œä»è€Œæœ‰æ•ˆèåˆæ–‡æœ¬å’Œæ—¶åºä¿¡æ¯ã€‚                                                                           |
| [Dual-Forecaster: A Multimodal Time Series Model Integrating Descriptive and Predictive Texts](https://arxiv.org/abs/2505.01135)   | arxiv | 2025.05 | Enhance time series with language.(Time series + Language IN, Time series OUT)            | Time Series Forecasting    | MLLM-based | â€”â€”                                                | 4070 Ti    | â€”â€”      | â€”â€”    | é€šè¿‡åŒæ—¶æ•´åˆä¸¤ç§ä¸åŒç±»å‹çš„æ–‡æœ¬â€”â€”æè¿°è¿‡å»çš„â€œå†å²æ–‡æœ¬â€å’Œé¢„ç¤ºæœªæ¥çš„â€œé¢„æµ‹æ–‡æœ¬â€ï¼Œå¹¶åˆ©ç”¨å¯¹æ¯”æŸå¤±ï¼Œäº¤å‰æ³¨æ„åŠ›æœºåˆ¶ç­‰è·¨æ¨¡æ€å¯¹é½æŠ€æœ¯å°†å®ƒä»¬ä¸æ—¶é—´åºåˆ—æ•°æ®æ·±åº¦èåˆï¼Œä»è€Œæ˜¾è‘—æå‡äº†é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚                                                                        |
| [Multimodal Conditioned Diffusive Time Series Forecasting](https://arxiv.org/abs/2504.19669)                                       | arxiv | 2025.04 | Enhance time series with language.(Time series + Language IN, Time series OUT)            | Time Series Forecasting    | MLLM-based | [Github](https://github.com/synlp/MCD-TSF)        | â€”â€”         | â€”â€”      | â€”â€”    | æå‡ºäº†ä¸€ä¸ªåä¸ºMCD-TSFçš„æ–°å‹æ‰©æ•£æ¨¡å‹ (diffusion model)ï¼Œå®ƒé€šè¿‡å°†æ—¶é—´æˆ³ (timestamps) å’Œæ–‡æœ¬æè¿° (texts) ä½œä¸ºä¸¤ç§ç‹¬ç«‹çš„å¤šæ¨¡æ€ä¿¡æ¯æ¥å…±åŒå¼•å¯¼å’Œå¢å¼ºæ—¶é—´åºåˆ—çš„é¢„æµ‹è¿‡ç¨‹ï¼Œå¹¶é€šè¿‡ç‰¹æ®Šæœºåˆ¶åŠ¨æ€æ§åˆ¶æ–‡æœ¬çš„å½±å“ï¼Œä»è€Œæ˜¾è‘—æå‡äº†é¢„æµ‹çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚                         |
| [TimeMaster: Training Time-Series Multimodal LLMs to Reason via Reinforcement Learning](https://arxiv.org/abs/2506.13705)          | arxiv | 2025.06 | Enhance time series with language.(Time series + Language IN, Language OUT)               | Time Series Classification | LLM-based  | [Github](https://github.com/langfengQ/TimeMaster) | 4*A100 GPU | â€”â€”      | â€”â€”    | æ—¶é—´åºåˆ—æ¨¡å‹æ— æ³•æ¨ç†ï¼Ÿé‚£æˆ‘å°±ç”¨å¤§è¯­è¨€æ¨¡å‹ä½œä¸ºåŸºç¡€æ¨¡å‹æ¥æ¨ç†ã€‚å¤§è¯­è¨€æ¨¡å‹å¯èƒ½å¯¹æ•°å­—æ²¡é‚£ä¹ˆæ•æ„Ÿï¼Ÿé‚£æˆ‘é€šè¿‡å¤šæ¨¡æ€æ¨¡å‹ç›´æ¥çœ‹å›¾ï¼Œå›¾ä¸­çš„æ³¢åŠ¨ç›¸è¾ƒäºæ•°å­—ï¼Œå¯èƒ½æ›´å¥½ç†è§£ã€‚                                                                                       |

## BenchmarkğŸ“ˆ
| Benchmark                                                                                                                      | Venue | Month   | Category                        | Code                                                  | Dataset                                               | Model | Brief                                                                                                                                                                                                 |
|--------------------------------------------------------------------------------------------------------------------------------|-------|---------|---------------------------------|-------------------------------------------------------|-------------------------------------------------------|-------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [MTBench: A Multimodal Time Series Benchmark for Temporal Reasoning and Question Answering](https://arxiv.org/abs/2410.18959) | arxiv | 2025.03 | Benchmark for language models   | [Github](https://github.com/Graph-and-Geometric-Learning/MTBench) | [Github](https://github.com/Graph-and-Geometric-Learning/MTBench) | â€”â€”    | è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é‡‘èå’Œå¤©æ°”é¢†åŸŸä¸­ç»“åˆæ—¶é—´åºåˆ—å’Œæ–‡æœ¬æ•°æ®è¿›è¡Œè”åˆæ¨ç†çš„èƒ½åŠ›ï¼Œè§£å†³äº†ç°æœ‰æ•°æ®é›†åœ¨è¯„ä¼°è·¨æ¨¡æ€æ¨ç†å’Œå¤æ‚é—®ç­”æ–¹é¢ä¸è¶³çš„é—®é¢˜ã€‚é€šè¿‡å¯¹æœ€å…ˆè¿›çš„LLMsè¿›è¡Œæµ‹è¯•ï¼Œç ”ç©¶å‘ç°å½“å‰æ¨¡å‹åœ¨æ•æ‰é•¿æœŸä¾èµ–ã€è§£é‡Šå› æœå…³ç³»ä»¥åŠæœ‰æ•ˆèåˆå¤šæ¨¡æ€ä¿¡æ¯æ–¹é¢å­˜åœ¨æ˜¾è‘—æŒ‘æˆ˜ï¼Œä½†åŠ å…¥æ–‡æœ¬ä¿¡æ¯é€šå¸¸èƒ½æé«˜æ—¶é—´åºåˆ—ä»»åŠ¡çš„å‡†ç¡®æ€§ã€‚ |
| [Context is Key](https://arxiv.org/abs/2410.18959)                                                                            | arxiv | 2024.1  | Benchmark for language models   | [Github](https://github.com/ServiceNow/context-is-key-forecasting) | [Github](https://github.com/ServiceNow/context-is-key-forecasting) | â€”â€”    | CiKåŸºå‡†å°†æ•°å€¼æ—¶é—´åºåˆ—æ•°æ®ä¸å¤šç§å…³é”®æ–‡æœ¬ä¸Šä¸‹æ–‡ç›¸ç»“åˆï¼Œå¹¶å¼•å…¥äº†Region of Interest CRPS (RCRPS)è¯„ä¼°æŒ‡æ ‡æ¥è¡¡é‡æ¨¡å‹çš„ä¸Šä¸‹æ–‡æ•´åˆèƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºLLMçš„é¢„æµ‹æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯é‡‡ç”¨â€œDIRECT PROMPTâ€æ–¹æ³•ï¼Œé€šè¿‡æœ‰æ•ˆåˆ©ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ˜¾è‘—ä¼˜äºçº¯æ•°å€¼æ¨¡å‹ï¼Œä½†åŒæ—¶ä¹Ÿæ­ç¤ºäº†å®ƒä»¬çš„ä¸€äº›å…³é”®å±€é™æ€§å’Œé«˜æ˜‚çš„æ¨ç†æˆæœ¬ã€‚ |
