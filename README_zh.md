# Multimodal-Time-Series-Papers
## Datasets
### Conference Papers📑
| Paper                                                                                                                                         | Venue        | Month   | Category               | Code                                                       | Dataset                                                                                                   | Model                                                                                                   | Brief                                                                                                                                       |
| --------------------------------------------------------------------------------------------------------------------------------------------- | ------------ | ------- | ---------------------- | ---------------------------------------------------------- | --------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------- |
| [ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset](https://arxiv.org/abs/2506.20093) | ICML 2025    | 2025.06 | QA_datasets+Multimodel | [Github](https://github.com/Pandalin98/ITFormer-ICML25)    | [Github](https://github.com/Pandalin98/ITFormer-ICML25)                                                   | ——                                                                                                      | 1. 提出了航空发动机多任务问答数据集**EngineMT‑QA**测试多模态时间序列模型的能力 <br>2. **ITFormer**结构让大模型可以看懂时间序列数据                                                        |
| [ChatTime: A Unified Multimodal Time Series Foundation Model Bridging Numerical and Textual Data](https://arxiv.org/abs/2412.11376)           | AAAI 2025    | 2024.12 | QA_datasets+Multimodel | [Github](https://github.com/ForestsKing/ChatTime)          | [Huggingface](https://huggingface.co/collections/ChengsenWang/chattime-datasets-6731b504efecc8a6e439741c) | [Huggingface](https://huggingface.co/collections/ChengsenWang/chattime-models-6731b650cb98bc7842713fde) | 将时间序列建模为一种外语，并构建了 ChatTime，一个用于时间序列和文本处理的统一框架。作为一个开箱即用的多模态时间序列基础模型，ChatTime 提供零样本预测能力，并支持时间序列和文本的双模态输入/输出。                                  |
| [Time-MQA: Time Series Multi-Task Question Answering with Context Enhancement](https://arxiv.org/abs/2503.01875)                              | ACL 2025     | 2025.02 | QA_datasets            | ——                                                         | [Huggingface](https://huggingface.co/Time-MQA)                                                            | [Huggingface](https://huggingface.co/Time-MQA)                                                          | 通过自然语言查询将多种时间序列分析任务统一起来，创建了一个包含约20万个问答对的大规模数据集TSQA。通过在TSQA数据集上对大型语言模型进行预训练，证明模型在解释时间序列模式和处理需要推理的复杂问题方面表现出显著增强的能力，从而将传统的数值任务与现代语言模型的推理能力相结合  |
| [Time-MMD: Multi-Domain Multimodal Dataset for Time Series Analysis](https://arxiv.org/abs/2406.08627)                                        | NuerIPS 2024 | 2024.06 | Multimodel_datasets    | [Github](https://github.com/AdityaLab/Time-MMD)            | [Github](https://github.com/AdityaLab/Time-MMD)                                                           | ——                                                                                                      | Time-MMD——首个覆盖9个不同领域、将数值序列与文本信息精细对齐的大型多模态数据集。同时，作者还开发了配套的软件库 MM-TSFlib，并通过大量实验证明，在这种高质量数据上结合文本信息可以使时间序列的预测准确率获得巨大提升（MSE平均降低超15%）。           |
| [Language Models Still Struggle to Zero-shot Reason about Time Series](https://arxiv.org/abs/2404.11757)                                      | ACL 2024     | 2024.04 | Multimodel_datasets    | [Github](https://github.com/behavioral-data/TSandLanguage) | [Github](https://github.com/behavioral-data/TSandLanguage)                                                | ——                                                                                                      | 通过创建一个全新的评估框架和数据集，来检验大型语言模型（LMs）是否真正具备对时间序列的推理能力，而不仅仅是进行模式匹配式的预测。研究发现，即使是像GPT-4这样强大的模型，在识别时间序列成因、回答相关问题等推理任务上表现也出人意料地差，其得分仅略高于随机猜测，远逊于人类水平。 |



## Models
### Conference Papers📑

| Paper                                                                                                                                            | Venue     | Month   | Category                                                                       | Tasks                   | Code                                                     | GPU                  | Dataset                                                                                                   | Model                                                                                                   | Brief                                                                                                                |
| ------------------------------------------------------------------------------------------------------------------------------------------------ | --------- | ------- | ------------------------------------------------------------------------------ | ----------------------- | -------------------------------------------------------- | -------------------- | --------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------- |
| [ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset](https://arxiv.org/abs/2506.20093)    | ICML 2025 | 2025.6  | QA_datasets+Multimodel                                                         | Time Series Analysis    | [Github](https://github.com/Pandalin98/ITFormer-ICML25)  | 4*H100               | [Github](https://github.com/Pandalin98/ITFormer-ICML25)                                                   | ——                                                                                                      | 1. 提出了航空发动机多任务问答数据集**EngineMT‑QA**测试多模态时间序列模型的能力<br> 2. **ITFormer**结构让大模型可以看懂时间序列数据                                 |
| [Time-VLM: Exploring Multimodal Vision-Language Models for Augmented Time Series Forecasting](https://arxiv.org/abs/2502.04395)                  | CVPR 2025 | 2025.02 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | [Github](https://github.com/CityMind-Lab/ICML25-TimeVLM) | RTX A6000 GPU (48GB) | ——                                                                                                        | ——                                                                                                      | 用预训练的视觉语言模型（VLMs）将时间、视觉和文本三种模态结合起来，以解决以往时间序列预测中仅使用单一模态（文本或视觉）进行增强所带来的局限性 。                                           |
| [TimeCAP: Learning to Contextualize, Augment, and Predict Time Series Events with Large Language Model Agents](https://arxiv.org/abs/2310.01728) | AAAI 2025 | 2025.02 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Analysis    | [Github](https://github.com/geon0325/TimeCAP)            | ——                   | [Github](https://github.com/geon0325/TimeCAP)                                                             | ——                                                                                                      | 创新性地使用两个独立的LLM agents来处理时间序列事件预测 。其中，第一个智能体负责将原始时间序列“情境化”为一份详尽的文本摘要，而第二个智能体则利用这份摘要（而非原始数据）进行更精准的预测，并通过一个多模态编码器进行协同增强 |
| [ChatTime: A Unified Multimodal Time Series Foundation Model Bridging Numerical and Textual Data](https://arxiv.org/abs/2412.11376)              | AAAI 2025 | 2024.12 | QA_datasets+Multimodel                                                         | Time Series Forecasting | [Github](https://github.com/ForestsKing/ChatTime)        | RTX 4090             | [Huggingface](https://huggingface.co/collections/ChengsenWang/chattime-datasets-6731b504efecc8a6e439741c) | [Huggingface](https://huggingface.co/collections/ChengsenWang/chattime-models-6731b650cb98bc7842713fde) | 将时间序列建模为一种外语，并构建了 ChatTime，一个用于时间序列和文本处理的统一框架。作为一个开箱即用的多模态时间序列基础模型，ChatTime 提供零样本预测能力，并支持时间序列和文本的双模态输入 / 输出。         |
| [GPT4MTS: Prompt-Based Large Language Model for Multimodal Time-Series Forecasting](https://ojs.aaai.org/index.php/AAAI/article/view/30383)      | AAAI 2024 | 2024.03 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | ——                                                       | ——                   | ——                                                                                                        | ——                                                                                                      | 提出一个框架，将文本信息作为一种可训练的**“软提示”**，放置在数值序列数据之前，以引导一个大语言模型（LLM）更有效地进行多模态时间序列预测                                             |
| [TIME-LLM: TIME SERIES FORECASTING BY REPROGRAMMING LARGE LANGUAGE MODELS](https://arxiv.org/abs/2310.01728)                                     | ICLR 2024 | 2023.1  | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | [Github](https://github.com/KimMeen/Time-LLM)            | 8*A800 (80GB)        | ——                                                                                                        | ——                                                                                                      | 通过重编程技术，将时间序列数据转化为大语言模型看的懂的语言，将时间序列预测巧妙地转化为了一个 LLM 可以直接处理的“类语言”任务                                                    |

### Preprint📚
| Paper                                                                                                                           | Venue     | Month   | Category                                                         | Tasks                  | Code                                                      | GPU        | Dataset | Model | Brief                                                                                                                                                                                                 |
|---------------------------------------------------------------------------------------------------------------------------------|-----------|---------|------------------------------------------------------------------|------------------------|-----------------------------------------------------------|------------|---------|-------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [ChronoSteer: Bridging Large Language Model and Time Series Foundation Model via Synthetic Data](https://arxiv.org/abs/2505.10083) | arxiv     | 2025.5  | Enhance time series with language.(Time series + Language IN, Time series OUT) | ——                     | ——                                                        | 4090 24GB  | ——      | ——    | 利用大型语言模型（LLM）将文本事件（如天气预报）转译为简单的“修订指令”（如“提高峰值”），用以直接引导一个时间序列模型（TSFM）做出更准确的预测，从而有效融合文本和时序信息。                                               |
| [Dual-Forecaster: A Multimodal Time Series Model Integrating Descriptive and Predictive Texts](https://arxiv.org/abs/2505.01135) | arxiv     | 2025.05 | Enhance time series with language.(Time series + Language IN, Time series OUT) | ——                     | ——                                                        | 4070 Ti    | ——      | ——    | 通过同时整合两种不同类型的文本——描述过去的“历史文本”和预示未来的“预测文本”，并利用对比损失，交叉注意力机制等跨模态对齐技术将它们与时间序列数据深度融合，从而显著提升了预测的准确性。                                         |
| [Multimodal Conditioned Diffusive Time Series Forecasting](https://arxiv.org/abs/2504.19669)                                    | arxiv     | 2025.04 | Enhance time series with language.(Time series + Language IN, Time series OUT) | ——                     | [Github](https://github.com/synlp/MCD-TSF)               | ——         | ——      | ——    | 提出了一个名为MCD-TSF的新型扩散模型 (diffusion model)，它通过将时间戳 (timestamps) 和文本描述 (texts) 作为两种独立的多模态信息来共同引导和增强时间序列的预测过程，并通过特殊机制动态控制文本的影响，从而显著提升了预测的准确性和鲁棒性。 |
