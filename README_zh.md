# Multimodal-Time-Series-Papers
## Datasets
### Conference Papers📑
| Paper                                                                                                                                         | Venue        | Month   | Category               | Code                                                       | Dataset                                                                                                   | Model                                                                                                   | Brief                                                                                                                                                                                         |
| --------------------------------------------------------------------------------------------------------------------------------------------- | ------------ | ------- | ---------------------- | ---------------------------------------------------------- | --------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset](https://arxiv.org/abs/2506.20093) | ICML 2025    | 2025.06 | QA_datasets+Multimodel | [Github](https://github.com/Pandalin98/ITFormer-ICML25)    | [Github](https://github.com/Pandalin98/ITFormer-ICML25)                                                   | ——                                                                                                      | 1. 提出了航空发动机多任务问答数据集**EngineMT‑QA**测试多模态时间序列模型的能力 <br> 2. **ITFormer**结构让大模型可以看懂时间序列数据                                                                                                         |
| [ChatTime: A Unified Multimodal Time Series Foundation Model Bridging Numerical and Textual Data](https://arxiv.org/abs/2412.11376)           | AAAI 2025    | 2025.05 | QA_datasets+Multimodel | [Github](https://github.com/ForestsKing/ChatTime)          | [Huggingface](https://huggingface.co/collections/ChengsenWang/chattime-datasets-6731b504efecc8a6e439741c) | [Huggingface](https://huggingface.co/collections/ChengsenWang/chattime-models-6731b650cb98bc7842713fde) | 将时间序列建模为一种外语，并构建了 ChatTime，一个用于时间序列和文本处理的统一框架。作为一个开箱即用的多模态时间序列基础模型，ChatTime 提供零样本预测能力，并支持时间序列和文本的双模态输入 / 输出。                                                                                  |
| [Time-MQA: Time Series Multi-Task Question Answering with Context Enhancement](https://arxiv.org/abs/2503.01875)                              | ACL 2025     | 2025.05 | QA_datasets            | ——                                                         | [Huggingface](https://huggingface.co/Time-MQA)                                                            | [Huggingface](https://huggingface.co/Time-MQA)                                                          | 通过自然语言查询将多种时间序列分析任务统一起来，创建了一个包含约20万个问答对的大规模数据集TSQA 。通过在TSQA数据集上对大型语言模型进行预训练，证明模型在解释时间序列模式和处理需要推理的复杂问题方面表现出显著增强的能力，从而将传统的数值任务与现代语言模型的推理能力相结合                                                   |
| [Time-MMD: Multi-Domain Multimodal Dataset for Time Series Analysis](https://arxiv.org/abs/2406.08627)                                        | NuerIPS 2024 | 2025.02 | Multimodel_datasets    | [Github](https://github.com/AdityaLab/Time-MMD)            | [Github](https://github.com/AdityaLab/Time-MMD)                                                           | ——                                                                                                      | Time-MMD——首个覆盖9个不同领域、将数值序列与文本信息精细对齐的大型多模态数据集。同时，作者还开发了配套的软件库 MM-TSFlib，并通过大量实验证明，在这种高质量数据上结合文本信息可以使时间序列的预测准确率获得巨大提升（MSE平均降低超15%）。                                                             |
| [Language Models Still Struggle to Zero-shot Reason about Time Series](https://arxiv.org/abs/2404.11757)                                      | ACL  2024    | 2024.12 | Multimodel_datasets    | [Github](https://github.com/behavioral-data/TSandLanguage) | [Github](https://github.com/behavioral-data/TSandLanguage)                                                | ——                                                                                                      | 数据集包含87,000对时间序列与文本描述，涵盖了医疗保健、金融、农业、交通、娱乐等10个领域。通过创建一个全新的评估框架和数据集，来检验大型语言模型（LMs）是否真正具备对时间序列的推理能力，而不仅仅是进行模式匹配式的预测 。研究发现，即使是像GPT-4这样强大的模型，在识别时间序列成因、回答相关问题等推理任务上表现也出人意料地差，其得分仅略高于随机猜测，远逊于人类水平 。 |
| [T2S: High-resolution Time Series Generation with Text-to-Series Diffusion Models](https://arxiv.org/abs/2505.02417)                          | IJCAI 2025   | 2024.06 | Multimodel_datasets    | [Github](https://github.com/WinfredGe/T2S)                 | [Github](https://github.com/WinfredGe/T2S)                                                                | ——                                                                                                      | 引入了一个包含超过60万个高分辨率时间序列-文本对的新数据集TSFragment-600K，以解决文本到时间序列生成领域中数据集稀缺和特定领域的问题 。其次，论文提出了一个名为T2S的、基于扩散的领域无关框架，该框架利用长度自适应变分自编码器和扩散变换器，能够根据自然语言描述生成任意长度的高保真时间序列 。                                    |
| [MoTime: A Dataset Suite for Multimodal Time Series Forecasting](https://arxiv.org/abs/2505.15072)                                            | arxiv        | 2024.04 | Multimodel_datasets    | ——                                                         | [Kaggle](https://www.kaggle.com/datasets/krissssss/multimodal-time-series-forecasting/)                   | ——                                                                                                      | MoTime是一套综合性的多模态时间序列预测数据集，通过整合多种数据源来提高预测准确性，解决了传统单模态方法的局限性，并为在不同历史数据和冷启动场景下的研究人员提供了宝贵的资源。                                                                                                     |
| [PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting](https://arxiv.org/abs/2210.08964)                              | TKDE         | 2022.09 | Multimodel_datasets    | [Github](https://github.com/HaoUNSW/PISA)                  | [Github](https://github.com/HaoUNSW/PISA)                                                                 | ——                                                                                                      | 将传统的数值输入输出序列转换为自然语言提示，从而将预测任务构建为一个句间生成问题，使得应用大型语言模型进行预测成为可能 。为了支持这一新任务，作者还发布了一个名为PISA的大规模数据集，该数据集包含三种真实的预测场景，并提供了一个基准来评估语言生成模型在此任务上的表现 。                                                      |

## Models
### Conference Papers📑
| Paper                                                                                                                                            | Venue        | Month   | Category                                                                       | Tasks                   | Algorithm       | Code                                                                      | GPU                     | Dataset                                                                                                   | Model                                                                                                   | Brief                                                                                                                                                       |
| ------------------------------------------------------------------------------------------------------------------------------------------------ | ------------ | ------- | ------------------------------------------------------------------------------ | ----------------------- | --------------- | ------------------------------------------------------------------------- | ----------------------- | --------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting](https://arxiv.org/abs/2310.09751)                         | www 2024     | 2023.10 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | MLLM-based      | [Github](https://github.com/DAMO-DI-ML/)                                  | A100 80GB               | [Github](https://github.com/DAMO-DI-ML/)                                                                  | ——                                                                                                      | 解决为不同时间序列领域构建专用模型（domain-specific）的局限性，从而实现跨领域的时间序列预测。该模型利用语言模型作为基础，通过引入“领域指令”来区分不同领域的数据并对齐两种模态，同时采用掩码（masking）策略来平衡不同领域的收敛速度，最终在多个基准测试中展现了卓越的预测性能和零样本迁移能力。 |
| [ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset](https://arxiv.org/abs/2506.20093)    | ICML 2025    | 2025.6  | QA_datasets+Multimodel                                                         | Time Series Analysis    | MLLM-based      | [Github](https://github.com/Pandalin98/ITFormer-ICML25)                   | 4*H100                  | [Github](https://github.com/Pandalin98/ITFormer-ICML25)                                                   | ——                                                                                                      | 1. 提出了航空发动机多任务问答数据集**EngineMT‑QA**测试多模态时间序列模型的能力 2. **ITFormer**结构让大模型可以看懂时间序列数据                                                                            |
| [T2S: High-resolution Time Series Generation with Text-to-Series Diffusion Models](https://arxiv.org/abs/2505.02417)                             | IJCAI 2025   | 2025.05 | Multimodel_datasets                                                            | Time Series Generation  | Diffusion-based | [Github](https://github.com/WinfredGe/T2S)                                | ——                      | [Github](https://github.com/WinfredGe/T2S)                                                                | ——                                                                                                      | 引入了一个包含超过60万个高分辨率时间序列-文本对的新数据集TSFragment-600K，以解决文本到时间序列生成领域中数据集稀缺和特定领域的问题。其次，论文提出了一个名为T2S的、基于扩散的领域无关框架，该框架利用长度自适应变分自编码器和扩散变换器，能够根据自然语言描述生成任意长度的高保真时间序列。    |
| [TimeCMA: Towards LLM-Empowered Multivariate Time Series Forecasting via Cross-Modality Alignment](https://arxiv.org/abs/2406.01638)             | AAAI 2025    | 2025.03 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | MLLM-based      | [Github](https://github.com/ChenxiLiu-HNU/TimeCMA)                        | NVIDIA A100 GPU         | ——                                                                                                        | ——                                                                                                      | TimeCMA通过双模态编码（时间序列编码与LLM赋能的提示编码）和跨模态对齐模块，利用基于相似度的检索从纠缠的提示嵌入中获取去耦且稳健的时间序列嵌入。                                                                                |
| [Time-VLM: Exploring Multimodal Vision-Language Models for Augmented Time Series Forecasting](https://arxiv.org/abs/2502.04395)                  | CVPR 2025    | 2025.02 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | MLLM-based      | [Github](https://github.com/CityMind-Lab/ICML25-TimeVLM)                  | RTX A6000 GPU (48GB)    | ——                                                                                                        | ——                                                                                                      | 用预训练的视觉语言模型（VLMs）将时间、视觉和文本三种模态结合起来，以解决以往时间序列预测中仅使用单一模态（文本或视觉）进行增强所带来的局限性。                                                                                   |
| [TimeCAP: Learning to Contextualize, Augment, and Predict Time Series Events with Large Language Model Agents](https://arxiv.org/abs/2310.01728) | AAAI2025     | 2025.02 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Analysis    | LLM-based       | [Github](https://github.com/geon0325/TimeCAP)                             | ——                      | [Github](https://github.com/geon0325/TimeCAP)                                                             | ——                                                                                                      | 创新性地使用两个独立的LLM agents来处理时间序列事件预测。其中，第一个智能体负责将原始时间序列“情境化”为一份详尽的文本摘要，而第二个智能体则利用这份摘要（而非原始数据）进行更精准的预测，并通过一个多模态编码器进行协同增强。                                        |
| [ChatTime: A Unified Multimodal Time Series Foundation Model Bridging Numerical and Textual Data](https://arxiv.org/abs/2412.11376)              | AAAI 2025    | 2024.12 | QA_datasets+Multimodel                                                         | Time Series Forecasting | MLLM-based      | [Github](https://github.com/ForestsKing/ChatTime)                         | NVIDIA GeForce RTX 4090 | [Huggingface](https://huggingface.co/collections/ChengsenWang/chattime-datasets-6731b504efecc8a6e439741c) | [Huggingface](https://huggingface.co/collections/ChengsenWang/chattime-models-6731b650cb98bc7842713fde) | 将时间序列建模为一种外语，并构建了ChatTime，一个用于时间序列和文本处理的统一框架。作为一个开箱即用的多模态时间序列基础模型，ChatTime 提供零样本预测能力，并支持时间序列和文本的双模态输入/输出。                                                   |
| [Time Series Forecasting with LLMs: Understanding and Enhancing Model Capabilities](https://arxiv.org/abs/2402.10835)                            | SIGKDD       | 2024.12 | Enhance time series with language.(Time series + Language IN, Language OUT)    | Time Series Forecasting | LLM-based       | [Github](https://github.com/MingyuJ666/Time-Series-Forecasting-with-LLMs) | ——                      | ——                                                                                                        | ——                                                                                                      | 探究了大型语言模型在零样本时间序列预测中的特性，发现它们在处理具有明显趋势和季节性模式的数据时表现更佳，并且能识别出数据中的潜在周期。论文提出了两种无需额外微调的性能提升方法：在提示中融入关于数据集的外部知识，以及将数值序列转述为自然语言描述，这两种方法都被证明能显著改善预测效果。               |
| [From News to Forecast: Integrating Event Analysis in LLM-Based Time Series Forecasting with Reflection](https://arxiv.org/abs/2409.17515)       | NeurIPS 2024 | 2024.09 | Enhance time series with language.(Time series + Language IN, Language OUT)    | Time Series Forecasting | LLM-based       | [Github](https://github.com/ameliawong1996/From_News_to_Forecast)         | ——                      | ——                                                                                                        | ——                                                                                                      | 通过整合大型语言模型（LLMs）和生成代理，将非结构化的新闻数据与数值时间序列相结合，从而增强了预测能力。研究利用基于LLM的代理来迭代式地筛选相关新闻，并通过类似人类的推理来评估预测，持续优化新闻选择逻辑，然后微调一个预训练的LLM来进行预测，实验结果表明该方法显著提高了预测的准确性。            |
| [GPT4MTS: Prompt-Based Large Language Model for Multimodal Time-Series Forecasting](https://ojs.aaai.org/index.php/AAAI/article/view/30383)      | AAAI 2024    | 2024.03 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | MLLM-based      | ——                                                                        | ——                      | ——                                                                                                        | ——                                                                                                      | 提出了一个通用流程，利用大型语言模型为时间序列数据收集和总结相关的文本信息，以解决多模态数据稀缺的问题。还提出了一种名为GPT4MTS的基于提示的LLM框架，该框架能同时利用数值和文本信息进行预测，并通过在一个新建的GDELT新闻影响数据集上进行实验，证明了其在多模态时间序列预测任务中的有效性。        |
| [S2IP‑LLM](https://arxiv.org/abs/2403.05798)                                                                                                     | ICML 2024    | 2024.03 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | LLM-based       | [Github](https://github.com/panzijie825/S2IP-LLM)                         | A100 80GB               | ——                                                                                                        | ——                                                                                                      | 首先将时间序列分解为趋势、季节性和残差部分以创建更具表现力的嵌入，然后通过最大化余弦相似度将其与从LLM词汇中提取的“语义锚点”对齐，并使用最相关的锚点作为提示来增强预测，最终在多个基准数据集上取得了优于现有顶尖方法的预测性能。                                          |
| [LLM Processes: Numerical Predictive Distributions Conditioned on Natural Language](https://arxiv.org/abs/2405.12856)                            | NeurIPS 2024 | 2024.03 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | LLM-based       | [Github](https://github.com/requeima/llm_processes)                       | 2*A100 80GB             | ——                                                                                                        | ——                                                                                                      | 利用大型语言模型（LLM）生成可处理任意位置数值数据的概率性预测，并且这些预测可以通过自然语言文本来引导和调整。通过开发有效的提示策略，该研究证明了LLMPs不仅在回归和预测任务上与高斯过程等专用模型具有竞争力，还能成功地将定性的文本描述融入定量预测中，从而利用LLMs中蕴含的丰富知识。            |
| [CAN LLMS UNDERSTAND TIME SERIES ANOMALIES?](https://arxiv.org/abs/2410.05440)                                                                   | ICLR 2025    | 2024.01 | Reasoning                                                                      | TIME SERIES ANOMALIES   | LLM-based       | [Github](https://github.com/rose-stl-lab/anomllm)                         | ——                      | ——                                                                                                        | ——                                                                                                      | 通过一系列受控实验，系统性地探究了大型语言模型（LLMs）是否真正理解时间序列中的异常。其核心发现颠覆了普遍认知：LLMs将时间序列作为图像理解时表现远好于文本，并且“链式思考”等引导其进行逻辑推理的提示反而会降低其性能，表明LLM对时序数据的理解机制并非源于其逻辑推理能力。                  |
| [Large Language Models Are Zero-Shot Time Series Forecasters](https://arxiv.org/abs/2310.07820)                                                  | NurIPS 2023  | 2023.01 | Enhance time series with language.(Time series + Language IN, Language OUT)    | Time Series Forecasting | LLM-based       | [Github](https://github.com/ngruver/llmtime)                              | ——                      | ——                                                                                                        | ——                                                                                                      | 通过将时间序列数据编码为数字字符串，成功地将时间序列预测问题转化为大语言模型（LLMs）的下一文本预测任务。研究发现，像GPT-3和LLaMA-2这样的大型语言模型，在无需针对特定任务进行训练的情况下（即零样本），其预测性能可以媲美甚至超越那些专门为时间序列任务构建和训练的模型。                |
| [TIME-LLM: TIME SERIES FORECASTING BY REPROGRAMMING LARGE LANGUAGE MODELS](https://arxiv.org/abs/2310.01728)                                     | ICLR 2024    | 2023.01 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | MLLM-based      | [Github](https://github.com/KimMeen/Time-LLM)                             | 8*A800 (80GB)           | ——                                                                                                        | ——                                                                                                      | 通过重编程技术，将时间序列数据转化为大语言模型看的懂的语言，将时间序列预测巧妙地转化为了一个 LLM 可以直接处理的“类语言”任务。                                                                                          |
| [PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting](https://arxiv.org/abs/2210.08964)                                 | TKDE 2023    | 2022.09 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | LLM-based       | [Github](https://github.com/HaoUNSW/PISA)                                 | ——                      | [Github](https://github.com/HaoUNSW/PISA)                                                                 | ——                                                                                                      | 将传统的数值输入输出序列转换为自然语言提示，从而将预测任务构建为一个句间生成问题，使得应用大型语言模型进行预测成为可能。为了支持这一新任务，作者还发布了一个名为PISA的大规模数据集，该数据集包含三种真实的预测场景，并提供了一个基准来评估语言生成模型在此任务上的表现。                      |


### Preprint📚
| Paper                                                                                                                              | Venue | Month   | Category                                                                                  | Tasks                      | Algorithm  | Code                                              | GPU        | Dataset | Model | Brief                                                                                                                                                                |
| ---------------------------------------------------------------------------------------------------------------------------------- | ----- | ------- | ----------------------------------------------------------------------------------------- | -------------------------- | ---------- | ------------------------------------------------- | ---------- | ------- | ----- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Time Series Forecasting as Reasoning: A Slow-Thinking Approach with Reinforced LLMs](https://arxiv.org/abs/2506.10630)            | arxiv | 2025.06 | Enhance time series with language.(Time series + Language IN, Time series + Language OUT) | ——                         | LLM-based  | [Github](https://github.com/lqzxt/Time-R1)        | 4*A800     | ——      | ——    | 提出了一种名为Time-R1的新颖框架，旨在通过训练大型语言模型（LLMs）具备“慢思考”能力，从而将时间序列预测从传统的模式匹配转变为一个显式的推理过程。该框架采用一个两阶段的强化微调方法：首先通过监督式微调进行预热，然后利用一种新的、带有细粒度多目标奖励的强化学习策略（GRIP）来优化模型的推理路径，从而显著提升预测性能。 |
| [ChronoSteer: Bridging Large Language Model and Time Series Foundation Model via Synthetic Data](https://arxiv.org/abs/2505.10083) | arxiv | 2025.05 | Enhance time series with language.(Time series + Language IN, Time series OUT)            | Time Series Forecasting    | MLLM-based | ——                                                | 4090 24GB  | ——      | ——    | 利用大型语言模型（LLM）将文本事件（如天气预报）转译为简单的“修订指令”（如“提高峰值”），用以直接引导一个时间序列模型（TSFM）做出更准确的预测，从而有效融合文本和时序信息。                                                                           |
| [Dual-Forecaster: A Multimodal Time Series Model Integrating Descriptive and Predictive Texts](https://arxiv.org/abs/2505.01135)   | arxiv | 2025.05 | Enhance time series with language.(Time series + Language IN, Time series OUT)            | Time Series Forecasting    | MLLM-based | ——                                                | 4070 Ti    | ——      | ——    | 通过同时整合两种不同类型的文本——描述过去的“历史文本”和预示未来的“预测文本”，并利用对比损失，交叉注意力机制等跨模态对齐技术将它们与时间序列数据深度融合，从而显著提升了预测的准确性。                                                                        |
| [Multimodal Conditioned Diffusive Time Series Forecasting](https://arxiv.org/abs/2504.19669)                                       | arxiv | 2025.04 | Enhance time series with language.(Time series + Language IN, Time series OUT)            | Time Series Forecasting    | MLLM-based | [Github](https://github.com/synlp/MCD-TSF)        | ——         | ——      | ——    | 提出了一个名为MCD-TSF的新型扩散模型 (diffusion model)，它通过将时间戳 (timestamps) 和文本描述 (texts) 作为两种独立的多模态信息来共同引导和增强时间序列的预测过程，并通过特殊机制动态控制文本的影响，从而显著提升了预测的准确性和鲁棒性。                         |
| [TimeMaster: Training Time-Series Multimodal LLMs to Reason via Reinforcement Learning](https://arxiv.org/abs/2506.13705)          | arxiv | 2025.06 | Enhance time series with language.(Time series + Language IN, Language OUT)               | Time Series Classification | LLM-based  | [Github](https://github.com/langfengQ/TimeMaster) | 4*A100 GPU | ——      | ——    | 时间序列模型无法推理？那我就用大语言模型作为基础模型来推理。大语言模型可能对数字没那么敏感？那我通过多模态模型直接看图，图中的波动相较于数字，可能更好理解。                                                                                       |

## Benchmark📈
| Benchmark                                                                                                                      | Venue | Month   | Category                        | Code                                                  | Dataset                                               | Model | Brief                                                                                                                                                                                                 |
|--------------------------------------------------------------------------------------------------------------------------------|-------|---------|---------------------------------|-------------------------------------------------------|-------------------------------------------------------|-------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [MTBench: A Multimodal Time Series Benchmark for Temporal Reasoning and Question Answering](https://arxiv.org/abs/2410.18959) | arxiv | 2025.03 | Benchmark for language models   | [Github](https://github.com/Graph-and-Geometric-Learning/MTBench) | [Github](https://github.com/Graph-and-Geometric-Learning/MTBench) | ——    | 评估大型语言模型在金融和天气领域中结合时间序列和文本数据进行联合推理的能力，解决了现有数据集在评估跨模态推理和复杂问答方面不足的问题。通过对最先进的LLMs进行测试，研究发现当前模型在捕捉长期依赖、解释因果关系以及有效融合多模态信息方面存在显著挑战，但加入文本信息通常能提高时间序列任务的准确性。 |
| [Context is Key](https://arxiv.org/abs/2410.18959)                                                                            | arxiv | 2024.1  | Benchmark for language models   | [Github](https://github.com/ServiceNow/context-is-key-forecasting) | [Github](https://github.com/ServiceNow/context-is-key-forecasting) | ——    | CiK基准将数值时间序列数据与多种关键文本上下文相结合，并引入了Region of Interest CRPS (RCRPS)评估指标来衡量模型的上下文整合能力。实验结果表明，基于LLM的预测模型，特别是采用“DIRECT PROMPT”方法，通过有效利用上下文信息，显著优于纯数值模型，但同时也揭示了它们的一些关键局限性和高昂的推理成本。 |
