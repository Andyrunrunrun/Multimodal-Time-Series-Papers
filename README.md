# Multimodal-Time-Series-Papers
## Datasets
### Conference PapersðŸ“‘
| Paper                                                                                                                                         | Venue        | Month   | Category               | Code                                                       | Dataset                                                                                                   | Model                                                                                                   |
| --------------------------------------------------------------------------------------------------------------------------------------------- | ------------ | ------- | ---------------------- | ---------------------------------------------------------- | --------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- |
| [ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset](https://arxiv.org/abs/2506.20093) | ICML 2025    | 2025.06 | QA_datasets+Multimodel | [Github](https://github.com/Pandalin98/ITFormer-ICML25)    | [Github](https://github.com/Pandalin98/ITFormer-ICML25)                                                   | â€”â€”                                                                                                      |
| [ChatTime: A Unified Multimodal Time Series Foundation Model Bridging Numerical and Textual Data](https://arxiv.org/abs/2412.11376)           | AAAI 2025    | 2025.05 | QA_datasets+Multimodel | [Github](https://github.com/ForestsKing/ChatTime)          | [Huggingface](https://huggingface.co/collections/ChengsenWang/chattime-datasets-6731b504efecc8a6e439741c) | [Huggingface](https://huggingface.co/collections/ChengsenWang/chattime-models-6731b650cb98bc7842713fde) |
| [Time-MQA: Time Series Multi-Task Question Answering with Context Enhancement](https://arxiv.org/abs/2503.01875)                              | ACL 2025     | 2025.05 | QA_datasets            | â€”â€”                                                         | [Huggingface](https://huggingface.co/Time-MQA)                                                            | [Huggingface](https://huggingface.co/Time-MQA)                                                          |
| [Time-MMD: Multi-Domain Multimodal Dataset for Time Series Analysis](https://arxiv.org/abs/2406.08627)                                        | NuerIPS 2024 | 2025.02 | Multimodel_datasets    | [Github](https://github.com/AdityaLab/Time-MMD)            | [Github](https://github.com/AdityaLab/Time-MMD)                                                           | â€”â€”                                                                                                      |
| [Language Models Still Struggle to Zero-shot Reason about Time Series](https://arxiv.org/abs/2404.11757)                                      | ACL  2024    | 2024.12 | Multimodel_datasets    | [Github](https://github.com/behavioral-data/TSandLanguage) | [Github](https://github.com/behavioral-data/TSandLanguage)                                                | â€”â€”                                                                                                      |
| [T2S: High-resolution Time Series Generation with Text-to-Series Diffusion Models](https://arxiv.org/abs/2505.02417)                          | IJCAI 2025   | 2024.06 | Multimodel_datasets    | [Github](https://github.com/WinfredGe/T2S)                 | [Github](https://github.com/WinfredGe/T2S)                                                                | â€”â€”                                                                                                      |
| [MoTime: A Dataset Suite for Multimodal Time Series Forecasting](https://arxiv.org/abs/2505.15072)                                            | arxiv        | 2024.04 | Multimodel_datasets    | â€”â€”                                                         | [Kaggle](https://www.kaggle.com/datasets/krissssss/multimodal-time-series-forecasting/)                   | â€”â€”                                                                                                      |
| [PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting](https://arxiv.org/abs/2210.08964)                              | TKDE         | 2022.09 | Multimodel_datasets    | [Github](https://github.com/HaoUNSW/PISA)                  | [Github](https://github.com/HaoUNSW/PISA)                                                                 | â€”â€”                                                                                                      |

## Models
### Conference PapersðŸ“‘
| Paper                                                                                                                                            | Venue        | Month   | Category                                                                       | Tasks                   | Algorithm       | Code                                                                      | GPU                     | Dataset                                                                                                   | Model                                                                                                   |
| ------------------------------------------------------------------------------------------------------------------------------------------------ | ------------ | ------- | ------------------------------------------------------------------------------ | ----------------------- | --------------- | ------------------------------------------------------------------------- | ----------------------- | --------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- |
| [UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting](https://arxiv.org/abs/2310.09751)                         | www 2024     | 2023.10 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | MLLM-based      | [Github](https://github.com/DAMO-DI-ML/)                                  | A100 80GB               | [Github](https://github.com/DAMO-DI-ML/)                                                                  | â€”â€”                                                                                                      |
| [ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset](https://arxiv.org/abs/2506.20093)    | ICML 2025    | 2025.6  | QA_datasets+Multimodel                                                         | Time Series Analysis    | MLLM-based      | [Github](https://github.com/Pandalin98/ITFormer-ICML25)                   | 4*H100                  | [Github](https://github.com/Pandalin98/ITFormer-ICML25)                                                   | â€”â€”                                                                                                      |
| [T2S: High-resolution Time Series Generation with Text-to-Series Diffusion Models](https://arxiv.org/abs/2505.02417)                             | IJCAI 2025   | 2025.05 | Multimodel_datasets                                                            | Time Series Generation  | Diffusion-based | [Github](https://github.com/WinfredGe/T2S)                                | â€”â€”                      | [Github](https://github.com/WinfredGe/T2S)                                                                | â€”â€”                                                                                                      |
| [TimeCMA: Towards LLM-Empowered Multivariate Time Series Forecasting via Cross-Modality Alignment](https://arxiv.org/abs/2406.01638)             | AAAI 2025    | 2025.03 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | MLLM-based      | [Github](https://github.com/ChenxiLiu-HNU/TimeCMA)                        | NVIDIA A100 GPU         | â€”â€”                                                                                                        | â€”â€”                                                                                                      |
| [Time-VLM: Exploring Multimodal Vision-Language Models for Augmented Time Series Forecasting](https://arxiv.org/abs/2502.04395)                  | CVPR 2025    | 2025.02 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | MLLM-based      | [Github](https://github.com/CityMind-Lab/ICML25-TimeVLM)                  | RTX A6000 GPU (48GB)    | â€”â€”                                                                                                        | â€”â€”                                                                                                      |
| [TimeCAP: Learning to Contextualize, Augment, and Predict Time Series Events with Large Language Model Agents](https://arxiv.org/abs/2310.01728) | AAAI2025     | 2025.02 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Analysis    | LLM-based       | [Github](https://github.com/geon0325/TimeCAP)                             | â€”â€”                      | [Github](https://github.com/geon0325/TimeCAP)                                                             | â€”â€”                                                                                                      |
| [ChatTime: A Unified Multimodal Time Series Foundation Model Bridging Numerical and Textual Data](https://arxiv.org/abs/2412.11376)              | AAAI 2025    | 2024.12 | QA_datasets+Multimodel                                                         | Time Series Forecasting | MLLM-based      | [Github](https://github.com/ForestsKing/ChatTime)                         | NVIDIA GeForce RTX 4090 | [Huggingface](https://huggingface.co/collections/ChengsenWang/chattime-datasets-6731b504efecc8a6e439741c) | [Huggingface](https://huggingface.co/collections/ChengsenWang/chattime-models-6731b650cb98bc7842713fde) |
| [Time Series Forecasting with LLMs: Understanding and Enhancing Model Capabilities](https://arxiv.org/abs/2402.10835)                            | SIGKDD       | 2024.12 | Enhance time series with language.(Time series + Language IN, Language OUT)    | Time Series Forecasting | LLM-based       | [Github](https://github.com/MingyuJ666/Time-Series-Forecasting-with-LLMs) | â€”â€”                      | â€”â€”                                                                                                        | â€”â€”                                                                                                      |
| [From News to Forecast: Integrating Event Analysis in LLM-Based Time Series Forecasting with Reflection](https://arxiv.org/abs/2409.17515)       | NeurIPS 2024 | 2024.09 | Enhance time series with language.(Time series + Language IN, Language OUT)    | Time Series Forecasting | LLM-based       | [Github](https://github.com/ameliawong1996/From_News_to_Forecast)         | â€”â€”                      | â€”â€”                                                                                                        | â€”â€”                                                                                                      |
| [GPT4MTS: Prompt-Based Large Language Model for Multimodal Time-Series Forecasting](https://ojs.aaai.org/index.php/AAAI/article/view/30383)      | AAAI 2024    | 2024.03 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | MLLM-based      | â€”â€”                                                                        | â€”â€”                      | â€”â€”                                                                                                        | â€”â€”                                                                                                      |
| [S2IPâ€‘LLM](https://arxiv.org/abs/2403.05798)                                                                                                     | ICML 2024    | 2024.03 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | LLM-based       | [Github](https://github.com/panzijie825/S2IP-LLM)                         | A100 80GB               | â€”â€”                                                                                                        | â€”â€”                                                                                                      |
| [LLM Processes: Numerical Predictive Distributions Conditioned on Natural Language](https://arxiv.org/abs/2405.12856)                            | NeurIPS 2024 | 2024.03 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | LLM-based       | [Github](https://github.com/requeima/llm_processes)                       | 2*A100 80GB             | â€”â€”                                                                                                        | â€”â€”                                                                                                      |
| [CAN LLMS UNDERSTAND TIME SERIES ANOMALIES?](https://arxiv.org/abs/2410.05440)                                                                   | ICLR 2025    | 2024.01 | Reasoning                                                                      | TIME SERIES ANOMALIES   | LLM-based       | [Github](https://github.com/rose-stl-lab/anomllm)                         | â€”â€”                      | â€”â€”                                                                                                        | â€”â€”                                                                                                      |
| [Large Language Models Are Zero-Shot Time Series Forecasters](https://arxiv.org/abs/2310.07820)                                                  | NurIPS 2023  | 2023.01 | Enhance time series with language.(Time series + Language IN, Language OUT)    | Time Series Forecasting | LLM-based       | [Github](https://github.com/ngruver/llmtime)                              | â€”â€”                      | â€”â€”                                                                                                        | â€”â€”                                                                                                      |
| [TIME-LLM: TIME SERIES FORECASTING BY REPROGRAMMING LARGE LANGUAGE MODELS](https://arxiv.org/abs/2310.01728)                                     | ICLR 2024    | 2023.01 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | MLLM-based      | [Github](https://github.com/KimMeen/Time-LLM)                             | 8*A800 (80GB)           | â€”â€”                                                                                                        | â€”â€”                                                                                                      |
| [PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting](https://arxiv.org/abs/2210.08964)                                 | TKDE 2023    | 2022.09 | Enhance time series with language.(Time series + Language IN, Time series OUT) | Time Series Forecasting | LLM-based       | [Github](https://github.com/HaoUNSW/PISA)                                 | â€”â€”                      | [Github](https://github.com/HaoUNSW/PISA)                                                                 | â€”â€”                                                                                                      |


### PreprintðŸ“š
| Paper                                                                                                                              | Venue | Month   | Category                                                                                  | Tasks                      | Algorithm  | Code                                              | GPU        | Dataset | Model |
| ---------------------------------------------------------------------------------------------------------------------------------- | ----- | ------- | ----------------------------------------------------------------------------------------- | -------------------------- | ---------- | ------------------------------------------------- | ---------- | ------- | ----- |
| [Time Series Forecasting as Reasoning: A Slow-Thinking Approach with Reinforced LLMs](https://arxiv.org/abs/2506.10630)            | arxiv | 2025.06 | Enhance time series with language.(Time series + Language IN, Time series + Language OUT) | â€”â€”                         | LLM-based  | [Github](https://github.com/lqzxt/Time-R1)        | 4*A800     | â€”â€”      | â€”â€”    |
| [ChronoSteer: Bridging Large Language Model and Time Series Foundation Model via Synthetic Data](https://arxiv.org/abs/2505.10083) | arxiv | 2025.05 | Enhance time series with language.(Time series + Language IN, Time series OUT)            | Time Series Forecasting    | MLLM-based | â€”â€”                                                | 4090 24GB  | â€”â€”      | â€”â€”    |
| [Dual-Forecaster: A Multimodal Time Series Model Integrating Descriptive and Predictive Texts](https://arxiv.org/abs/2505.01135)   | arxiv | 2025.05 | Enhance time series with language.(Time series + Language IN, Time series OUT)            | Time Series Forecasting    | MLLM-based | â€”â€”                                                | 4070 Ti    | â€”â€”      | â€”â€”    |
| [Multimodal Conditioned Diffusive Time Series Forecasting](https://arxiv.org/abs/2504.19669)                                       | arxiv | 2025.04 | Enhance time series with language.(Time series + Language IN, Time series OUT)            | Time Series Forecasting    | MLLM-based | [Github](https://github.com/synlp/MCD-TSF)        | â€”â€”         | â€”â€”      | â€”â€”    |
| [TimeMaster: Training Time-Series Multimodal LLMs to Reason via Reinforcement Learning](https://arxiv.org/abs/2506.13705)          | arxiv | 2025.06 | Enhance time series with language.(Time series + Language IN, Language OUT)               | Time Series Classification | LLM-based  | [Github](https://github.com/langfengQ/TimeMaster) | 4*A100 GPU | â€”â€”      | â€”â€”    |

## BenchmarkðŸ“ˆ
| Benchmark                                                                                                                     | Venue | Month   | Category                      | Code                                                               | Dataset                                                            | Model |
| ----------------------------------------------------------------------------------------------------------------------------- | ----- | ------- | ----------------------------- | ------------------------------------------------------------------ | ------------------------------------------------------------------ | ----- |
| [MTBench: A Multimodal Time Series Benchmark for Temporal Reasoning and Question Answering](https://arxiv.org/abs/2410.18959) | arxiv | 2025.03 | Benchmark for language models | [Github](https://github.com/Graph-and-Geometric-Learning/MTBench)  | [Github](https://github.com/Graph-and-Geometric-Learning/MTBench)  | â€”â€”    |
| [Context is Key](https://arxiv.org/abs/2410.18959)                                                                            | arxiv | 2024.1  | Benchmark for language models | [Github](https://github.com/ServiceNow/context-is-key-forecasting) | [Github](https://github.com/ServiceNow/context-is-key-forecasting) | â€”â€”    |
